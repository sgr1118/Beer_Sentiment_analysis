{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "54879d0615c64127aee13e0f2f6f0a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a9bb6d5a99a4c7f8f582effcaac659e",
              "IPY_MODEL_f432e6464eff4ebdaf32a2768500289c",
              "IPY_MODEL_af9b7266371c464d8cecc9e45299026d"
            ],
            "layout": "IPY_MODEL_f0815602206544d4ad3e8cf1bb3f9fc7"
          }
        },
        "3a9bb6d5a99a4c7f8f582effcaac659e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0722d710ee00488cbe74a3ab0af7812e",
            "placeholder": "​",
            "style": "IPY_MODEL_bf52763e29b846d0b30e631c9f4e83fa",
            "value": "Downloading (…)ve/main/spiece.model: 100%"
          }
        },
        "f432e6464eff4ebdaf32a2768500289c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbf65b46a9be4036a9caa955e2e0ab03",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb26a34032dd42eca506aab065756c1b",
            "value": 791656
          }
        },
        "af9b7266371c464d8cecc9e45299026d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d64de23fc15c41df93b4bf81870d5d12",
            "placeholder": "​",
            "style": "IPY_MODEL_485f382b60b54238957472fb70afd539",
            "value": " 792k/792k [00:00&lt;00:00, 3.06MB/s]"
          }
        },
        "f0815602206544d4ad3e8cf1bb3f9fc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0722d710ee00488cbe74a3ab0af7812e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf52763e29b846d0b30e631c9f4e83fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbf65b46a9be4036a9caa955e2e0ab03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb26a34032dd42eca506aab065756c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d64de23fc15c41df93b4bf81870d5d12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "485f382b60b54238957472fb70afd539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "071833cf4a014c359095d41939544c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0564ffe7e93c4d8dbc8080f413b7cc36",
              "IPY_MODEL_73c655fa889e4dc2bb02b2b8dd41faa8",
              "IPY_MODEL_26e4db7dfbd249f59a8e4f38aa05b200"
            ],
            "layout": "IPY_MODEL_a5cb88aa738f4093b8fb9c6bfa15c239"
          }
        },
        "0564ffe7e93c4d8dbc8080f413b7cc36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31aa0011b51f420585e7623fceebf839",
            "placeholder": "​",
            "style": "IPY_MODEL_93560a90b16b41a4ab78ec4ac87ed054",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "73c655fa889e4dc2bb02b2b8dd41faa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1775c9f0acf744a3ba06e590c59fc8b7",
            "max": 1208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c21ef057c22a450691909670efce3045",
            "value": 1208
          }
        },
        "26e4db7dfbd249f59a8e4f38aa05b200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d11285e898a473ab422b03c1e94b62d",
            "placeholder": "​",
            "style": "IPY_MODEL_0bb0653659b34a52bc028708aa41a9a6",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 47.9kB/s]"
          }
        },
        "a5cb88aa738f4093b8fb9c6bfa15c239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31aa0011b51f420585e7623fceebf839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93560a90b16b41a4ab78ec4ac87ed054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1775c9f0acf744a3ba06e590c59fc8b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c21ef057c22a450691909670efce3045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d11285e898a473ab422b03c1e94b62d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bb0653659b34a52bc028708aa41a9a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x42WUZK47kWf",
        "outputId": "63b0dd58-71c1-4ae2-ac44-c28569eba7b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjQdifH2eWmW"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "# !pip install pytorch_lightning==1.2.10\n",
        "!pip install pytorch_lightning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datsets transformers[sentencepiece]\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "qIoserLd76jQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pl.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09Bi_A4K25Da",
        "outputId": "0f32bc8b-2b78-4970-cf25-a4d0a85e033c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 불러오기\n",
        "\n",
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import logging\n",
        "import random\n",
        "import re\n",
        "from itertools import chain\n",
        "from string import punctuation\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kff-oic8ehCP",
        "outputId": "4f98c90f-53fb-4e7c-bddf-0fba7bd805c9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed): # 랜덤 적용\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "ekiPPqGRe4hB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델링\n",
        "- 파이토치 라이트닝을 사용한다."
      ],
      "metadata": {
        "id": "NiyOXFdrfKdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class T5FineTuner(pl.LightningModule):\n",
        "    # def __init__(self, hparams):\n",
        "    #     super(T5FineTuner, self).__init__() #  모델과 토크나이저를 불러옵니다.\n",
        "    #     self.hparams = hparams\n",
        "    # def __init__(self, **hparams):\n",
        "    #     super(T5FineTuner, self).__init__() #  모델과 토크나이저를 불러옵니다.\n",
        "    #     self.save_hyperparameters()\n",
        "    def __init__(self, hparams):\n",
        "        super(T5FineTuner, self).__init__()\n",
        "        self.save_hyperparameters(hparams)\n",
        "\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n",
        "        self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n",
        "\n",
        "    def is_logger(self): # 현재 모델 학습을 수행하는 프로세스의 랭크(rank)\n",
        "        return self.trainer.proc_rank <= 0 \n",
        "        # 첫 번째 프로세스에서만 로그를 출력하도록 하여 로깅을 중복되지 않도록 하는데 사용된다.\n",
        "\n",
        "    def forward(\n",
        "        self, input_ids, attention_mask = None, decoder_input_ids = None, decoder_attention_mask = None,\n",
        "        lm_labels = None): # 순전파\n",
        "\n",
        "        return self.model(input_ids, \n",
        "                          attention_mask = attention_mask, \n",
        "                          decoder_input_ids = decoder_input_ids,\n",
        "                          decoder_attention_mask = decoder_attention_mask, \n",
        "                          lm_labels = lm_labels)\n",
        "        \n",
        "    def _step(self, batch): # 모델에 입력을 주고 손실을 계산한 후 손실값을 반환\n",
        "        lm_labels = batch['target_ids'] # 입력 데이터에서 생성된 타겟 시퀀스를 저장\n",
        "        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100 # 모델이 패딩 토큰을 예측하지 못하도록 막는다.\n",
        "\n",
        "        outputs = self(input_ids = batch['source_ids'],\n",
        "                    attention_mask = batch['source_mask'],\n",
        "                    lm_labels = lm_labels,\n",
        "                    decoder_attention_mask=batch['target_mask'])\n",
        "        \n",
        "        loss = outputs[0]\n",
        "\n",
        "        return loss # 손실값 반환\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss = self._step(batch)\n",
        "\n",
        "        tensorboard_logs = {'train_loss' : loss} # 학습 단계에서의 손실값을 계산합니다. \n",
        "        return {'loss' : loss, 'log' : tensorboard_logs} # tensorboard에 로그를 기록하고 손실값을 반환합니다.\n",
        "\n",
        "    def training_epoch_end(self, outputs): # epoch마다 계산된 손실값의 평균값을 반환한다.\n",
        "        avg_train_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
        "        tensorboard_logs = {'avg_train_loss' : avg_train_loss}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx): #  검증 단계에서의 손실값을 계산합니다.\n",
        "        loss = self._step(batch)\n",
        "        return {'val_loss' : loss}\n",
        "\n",
        "    def validation_epoch_end(self, outputs): # epoch마다 계산된 검증 손실값의 평균값을 반환한다.\n",
        "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
        "        tensorboard_logs = {'val_loss' : avg_loss}\n",
        "        return {'avg_val_loss' : avg_loss, 'log' : tensorboard_logs, 'progress_bar' : tensorboard_logs}\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # 옵티마이저와 스케줄러를 정의한다.\n",
        "\n",
        "        model = self.model\n",
        "        no_decay = ['bias', 'LayerNorm.weight']\n",
        "        optimizer_grouped_parameters = [\n",
        "            {'params' : [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "             'weight_decay' : self.hparams.weight_decay}, # 가중치 감쇠 적용\n",
        "\n",
        "             {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "             \"weight_decay\": 0.0} # 이 그룹에 속한 파라미터는 가중치 감쇠를 적용하지 않는다\n",
        "        ] # 각 파라미터 그업에 대해 서로 다른 가중치 감쇠를 적용한다.\n",
        "\n",
        "        optimizer = AdamW(optimizer_grouped_parameters, lr = self.hparams.leraning_rate, eps = self.hparams.adam_epsilon)\n",
        "        self.opt = optimizer\n",
        "        return [optimizer]\n",
        "\n",
        "    def get_tqdm_dict(self): #  tqdm에 표시할 딕셔너리를 반환합니다.\n",
        "        tqdm_dict = {'loss' : '{:.3f}'.format(self.trainer.avg_loss), 'lr' : self.lr_schedulers.get_last_lr()[-1]}\n",
        "        # 평균 손실 값을 소수점 세 자리까지 표시하고, 현재의 학습률을 표시\n",
        "\n",
        "        return tqdm_dict\n",
        "\n",
        "    def train_dataloader(self): # 학습 데이터 정의\n",
        "        train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"train\", args=self.hparams)\n",
        "        dataloader = DataLoader(train_dataset, batch_size = self.hparams.train_batch_size, drop_last=True, shuffle=True, num_workers=4)\n",
        "\n",
        "        t_total = (\n",
        "            (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n",
        "            // self.hparams.gradient_accumulation_steps * float(self.hparams.num_train_epoch)\n",
        "        )\n",
        "\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            self.opt, num_warmup_steps = self.hparams.warmup_steps, num_training_steps = t_total\n",
        "        ) # get_linear_schedule_with_warmup : 옵티마이저와 학습률을 설정한다.\n",
        "          # 초기에 0에서 시작하여 지정된 에포크마다 선형적으로 증가하고 단계를 거친 후 다시 선형적으로 감소시키는 방식으로 학습률을 조정한다.\n",
        "          # num_warmup_steps : warmup 단계의 epoch \n",
        "          # num_training_steps : 전체 학습을 마칠 때까지 optimizer가 업데이트되는 횟수\n",
        "        self.lr_schedulers = scheduler\n",
        "        return dataloader\n",
        "\n",
        "    def val_dataloader(self): # 검증 데이터 정의\n",
        "        val_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"val\", args=self.hparams)\n",
        "        return DataLoader(val_dataset, batch_size = self.hparams.eval_batch_size, num_workers = 4)"
      ],
      "metadata": {
        "id": "P2n_ZMnRfO9P"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# on_validation_end, on_test_end 오버라이드\n",
        "\n",
        "class LoggingCallback(pl.Callback): # 학습 중 결과를 로깅하고 파일에 저장한다.\n",
        "    def on_validation_end(self, trainer, pl_module):\n",
        "        logger.info('-- Validation results --')\n",
        "        if pl_module.is_logger():\n",
        "            metrics = trainer.callback_metrics\n",
        "\n",
        "            # 로그 결과\n",
        "            for key in sorted(metrics):\n",
        "                if key not in ['log', 'pregress_bar']:\n",
        "                    logger.info('{} = {}\\n'.format(key, str(metrics[key])))\n",
        "\n",
        "    def on_test_end(self, trainer, pl_module):\n",
        "        logger.info('-- Test results --')\n",
        "\n",
        "        if pl_module.is_logger():\n",
        "            metrics = trainer.callback_metrics\n",
        "\n",
        "            # 로그외 결과를 파일로 저장한다.\n",
        "            output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n",
        "            with open(output_test_results_file, \"w\") as writer:\n",
        "                for key in sorted(metrics):\n",
        "                    if key not in [\"log\", \"progress_bar\"]:\n",
        "                        logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "                        writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"
      ],
      "metadata": {
        "id": "4774bxW2y-K_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 하이퍼 매개변수 및 기타 인수를 정의해 보겠습니다. 필요에 따라 특정 작업에 대해 이 사전을 재정의할 수 있습니다. 대부분의 경우 data_dir 및 output_dir만 변경하면 됩니다.\n",
        "\n",
        "### 여기서 배치 크기는 8이고 gradient_accumulation_steps는 16이므로 효과적인 배치 크기는 128입니다."
      ],
      "metadata": {
        "id": "4o5xBhhB08ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args_dict = dict(\n",
        "    data_dir = '', # 데이터 경로\n",
        "    output_dir = '', # 체크포인트 경로\n",
        "    model_name_or_path = 't5-base',\n",
        "    tokenizer_name_or_path = 't5-base',\n",
        "    max_seq_length = 512, # 입력 시퀀스의 최대 길이\n",
        "    learning_rate = 3e-4, # 학습률\n",
        "    weight_decay = 0.0, # L2 가중치 감쇠를 위한 파라미터\n",
        "    adam_epsilon = 1e-8, # Adam optimizer에서 epsilon 값\n",
        "    warmup_steps = 0, # learning rate scheduler에서 warmup steps\n",
        "    train_batch_size = 8, # 훈련 배치 사이즈\n",
        "    eval_train_size = 8, # 평가 배치 사이즈\n",
        "    num_train_epochs = 2, # 에포크 수\n",
        "    gradient_accumulation_steps = 16, # accumulation_steps의 수\n",
        "    n_gpu = 1, # 사용할 gpu 수\n",
        "    early_stop_callback = False, # early stopping 여부\n",
        "    fp_16 = False, # mixed precision training 사용 여부\n",
        "    opt_level = '01', # mixed precision training 시 사용할 최적화 레벨\n",
        "    max_grad_norm = 1.0, # gradient clipping을 위한 최대 그래디언트 norm 값\n",
        "    seed = 42 # random seed 값\n",
        ")"
      ],
      "metadata": {
        "id": "lHMKBn7I06NE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xvf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "id": "nZpRrVLw6abF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos_files = glob.glob('aclImdb/train/pos/*.txt')\n",
        "train_neg_files = glob.glob('aclImdb/train/neg/*.txt')"
      ],
      "metadata": {
        "id": "CuG52LmF6emd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_pos_files), len(train_neg_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MBzvszw6fRu",
        "outputId": "3553d0e5-40b0-4936-9db7-6063becd002f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12500, 12500)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 검증을 위하여 훈련 데이터 셋에서 2000개를 추출하고 긍정/부정 리뷰를 각 1000개씩 val 디렉토리에 저장한다."
      ],
      "metadata": {
        "id": "2QDFyKlS6o2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir aclImdb/val aclImdb/val/pos aclImdb/val/neg"
      ],
      "metadata": {
        "id": "ZFDP5UAZ6oVK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(train_pos_files)\n",
        "random.shuffle(train_neg_files)\n",
        "\n",
        "val_pos_files = train_pos_files[:1000]\n",
        "val_neg_files = train_neg_files[:1000]"
      ],
      "metadata": {
        "id": "cHNwiOSr62Py"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil"
      ],
      "metadata": {
        "id": "bb-EmaRx66iq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 이동\n",
        "\n",
        "for f in val_pos_files: \n",
        "  shutil.move(f,  'aclImdb/val/pos')\n",
        "for f in val_neg_files:\n",
        "  shutil.move(f,  'aclImdb/val/neg')"
      ],
      "metadata": {
        "id": "X0RXnWMA67WX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터셋 준비"
      ],
      "metadata": {
        "id": "-q3VFiqW7Ota"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210,
          "referenced_widgets": [
            "54879d0615c64127aee13e0f2f6f0a97",
            "3a9bb6d5a99a4c7f8f582effcaac659e",
            "f432e6464eff4ebdaf32a2768500289c",
            "af9b7266371c464d8cecc9e45299026d",
            "f0815602206544d4ad3e8cf1bb3f9fc7",
            "0722d710ee00488cbe74a3ab0af7812e",
            "bf52763e29b846d0b30e631c9f4e83fa",
            "dbf65b46a9be4036a9caa955e2e0ab03",
            "eb26a34032dd42eca506aab065756c1b",
            "d64de23fc15c41df93b4bf81870d5d12",
            "485f382b60b54238957472fb70afd539",
            "071833cf4a014c359095d41939544c61",
            "0564ffe7e93c4d8dbc8080f413b7cc36",
            "73c655fa889e4dc2bb02b2b8dd41faa8",
            "26e4db7dfbd249f59a8e4f38aa05b200",
            "a5cb88aa738f4093b8fb9c6bfa15c239",
            "31aa0011b51f420585e7623fceebf839",
            "93560a90b16b41a4ab78ec4ac87ed054",
            "1775c9f0acf744a3ba06e590c59fc8b7",
            "c21ef057c22a450691909670efce3045",
            "1d11285e898a473ab422b03c1e94b62d",
            "0bb0653659b34a52bc028708aa41a9a6"
          ]
        },
        "id": "ks4NBFIf7SUF",
        "outputId": "7cffe2b8-9b0b-47a3-909a-825e44f0c53f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54879d0615c64127aee13e0f2f6f0a97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "071833cf4a014c359095d41939544c61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 감정 토큰화\n",
        "\n",
        "ids_neg = tokenizer.encode('negative </s>')\n",
        "ids_pos = tokenizer.encode('positive </s>')\n",
        "print(len(ids_neg), len(ids_pos))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OH0ysuvZ8184",
        "outputId": "63591200-92e5-47f1-cfa1-9b37813a1b9f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:226: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 리뷰가 긍정적이라면 긍정적, 부정적이라면 부정적으로 인코딩된다.\n",
        "\n",
        "### html 태그를 제거하여 리뷰 텍스트를 정리한다. 또한 T5 모델에서 요구하는 입력 및 대상 끝에 eos 토큰 </s>를 추가한다."
      ],
      "metadata": {
        "id": "UcYKu-M89UcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImdbDataset(Dataset): # 리뷰 데이터셋을 처리하는 데이터셋 클래스\n",
        "    def __init__(self, tokenizer, data_dir, type_path, max_len = 512): # () 안에 인스턴스 변수 초기화\n",
        "        self.pos_file_path = os.path.join(data_dir, type_path, 'pos')\n",
        "        self.neg_file_path = os.path.join(data_dir, type_path, 'neg')\n",
        "\n",
        "        self.pos_files = glob.glob(\"%s/*.txt\" % self.pos_file_path)\n",
        "        self.neg_files = glob.glob(\"%s/*.txt\" % self.neg_file_path)\n",
        "\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = tokenizer\n",
        "        self.inputs = []\n",
        "        self.targets = []\n",
        "\n",
        "        self._build()\n",
        "\n",
        "    def __len__(self): # inputs 길이 반환\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, index): # source_ids, source_mask, target_ids, target_mask를 딕셔너리 형태로 반환\n",
        "    # source_ids와 target_ids는 squeeze를 사용하여 1차원으로 변경\n",
        "        source_ids = self.inputs[index]['input_ids'].squeeze()\n",
        "        target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
        "\n",
        "        src_mask = self.inputs[index]['attention_mask'].squeeze()\n",
        "        target_mask = self.targets[index]['attention_mask'].squeeze()\n",
        "\n",
        "        return {'source_ids' : source_ids, 'source_mask' : src_mask, 'target_ids' : target_ids, 'target_mask' : target_mask}\n",
        "\n",
        "    def _build(self): # 해당 폴더에서 파일을 가져와 self._buil_examples_from_files 메서드 호출\n",
        "        self._build_examples_from_files(self.pos_files, 'positive')\n",
        "        self._build_examples_from_files(self.neg_files, 'negative')\n",
        "\n",
        "    def _build_examples_from_files(self, files, sentiment): # 파일을 받아와 전처리 적용\n",
        "        REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
        "        REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
        "\n",
        "        for path in files:\n",
        "            with open(path, 'r') as f:\n",
        "                text = f.read()\n",
        "\n",
        "            line = text.strip()\n",
        "            line = REPLACE_NO_SPACE.sub('', line)\n",
        "            line = REPLACE_WITH_SPACE.sub('', line)\n",
        "            line = line + ' </s>'\n",
        "\n",
        "            target = sentiment + \" </s>\"\n",
        "\n",
        "            # tokenize inputs\n",
        "            tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
        "                [line], max_length = self.max_len, pad_to_max_length = True, return_tensors = 'pt'\n",
        "            )\n",
        "\n",
        "            # tokenize targets\n",
        "            tokenized_targets = self.tokenizer.batch_encode_plus(\n",
        "                [target], max_length = 2, pad_to_max_length = True, return_tensors = 'pt'\n",
        "            ) # max_length가 2인 이유는 감성 레이블을 대표하는 토큰이기 때문이다.\n",
        "\n",
        "            self.inputs.append(tokenized_inputs)\n",
        "            self.targets.append(tokenized_targets)"
      ],
      "metadata": {
        "id": "k5E-aYKY9T68"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ImdbDataset(tokenizer, 'aclImdb', 'val',  max_len=512)\n",
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OiKaV9y9MbY",
        "outputId": "94a51177-82a5-412e-9be6-d10f6257e238"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataset[28]\n",
        "print(tokenizer.decode(data['source_ids']))\n",
        "print(tokenizer.decode(data['target_ids']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3VsqbPky5AF",
        "outputId": "3703c790-288f-4b39-8338-41c0b3e31f20"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frailty is a nongory horror film that achieves its chills by following the logic and impact of a mans delusionobsession straight into depravity Dad we never learn his name is a gentle man and loving father whos raising his sons alone after Mom died giving birth to the youngest son Adam The familys world flips upside down late one night when Dad rushes into the boys room and tells them God has given him a vision And what a vision <unk> the entire familys job is to destroy demons who of course are disguised in human formProceeding from this premise the movie is unflinching in following it Dad kidnaps peopledemons whom God has told him to destroy binds them lays his hand on them to see a vision of their evil then kills them <unk> while making his young sons watch Fenton the older boy is horrified seeing only a father whos turned into a crazed murderer Adam the younger is uncomfortable but trusts that Dad is following Gods will Eventually Dad takes his sons on missions to abduct the demons that God has put on Dads list and finally invites them to fully participate in Gods mission for the familyThis is not you understand an abusive father He loves his children He is only following Gods instructions This is our job now son Weve got to do this When Fenton terrified and convinced his father has gone mad says hell report him to the police his father explains If you do that son Ill die The angel was clear on this The pressure that the children are under is unbearable and tragic and warps their entire lives1 The movies structure is similar to the one used in The Usual Suspects a story in flashback told in a police station to a FBI agent The moody lighting the stormy weather and the eerie calm in the present day add to the menace of the backstory I wanted to believe the unfolding horror was just a story until I remembered the reallife parallel of Andrea Yates who believed she was possessed by Satan and could save her children by drowning them Even then I wanted to believe that I was watching a human tragedy rather than a story of divine retributionThe movie gave me no such comfort though as it gave strong clues at the end about the veracity of Dads</s>\n",
            "positive</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 훈련"
      ],
      "metadata": {
        "id": "Wsv8IYcpFJHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p t5_imdb_sentiment # 디렉토리 생성"
      ],
      "metadata": {
        "id": "dsAsZpd8DigO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch Lightning 2.0.2를 사용함에 따라 pl.callbacks.ModelCheckpoint에 keyword argument가 조금 변경되었다."
      ],
      "metadata": {
        "id": "givdIHF43Gyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력된 인자를 args.dict에 저장\n",
        "args_dict.update({'data_dir': 'aclImdb', 'output_dir': 't5_imdb_sentiment', 'num_train_epochs' : 2})\n",
        "args = argparse.Namespace(**args_dict) # args 변수에 저장\n",
        "\n",
        "\n",
        "# checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "#     filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",
        "# ) 원본\n",
        "\n",
        "# 수정된 코드\n",
        "# 학습 과정에서 모델의 가중치를 저장\n",
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "    dirpath = args.output_dir, save_last = 'checkpoint', monitor = 'val_loss', mode = 'min', save_top_k = 5)\n",
        "\n",
        "# 토치 라이트닝 2.0.2에서 gpus를 accelerator로 변경해주어야 합니다.\n",
        "# early_stop_callback을 early_stopping_callback으로 수정해주어야 합니다.\n",
        "train_params = dict(\n",
        "    accumulate_grad_batches = args.gradient_accumulation_steps,\n",
        "    accelerator = args.n_gpu, # 수정한 부분 - 1\n",
        "    max_epochs = args.num_train_epochs,\n",
        "    early_stop_callback = False,\n",
        "    precision = 16 if args.fp_16 else 32,\n",
        "    amp_level = args.opt_level,\n",
        "    gradient_clip_val = args.max_grad_norm,\n",
        "    checkpoint_callback=checkpoint_callback,\n",
        "    callbacks = [LoggingCallback()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "Az20VETe0sru",
        "outputId": "a69d146d-3211-41a2-b8bf-1fc6daf61d6e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-583cf7de08e7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_stopping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 입력된 인자를 args.dict에 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0margs_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'data_dir'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'aclImdb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output_dir'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m't5_imdb_sentiment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_train_epochs'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs_dict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# args 변수에 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lightning'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 세트를 반환하도록 get_dataset 함수를 정의합니다. 모델은 이 함수를 호출하여 train 및 val 데이터 세트를 가져옵니다\n",
        "\n",
        "### 모델 코드를 전혀 수정할 필요가 없도록 데이터 세트 함수를 정의하고 있습니다. 문제에 따라 다른 데이터 세트를 반환하도록 함수를 재정의합니다. 이것이 현재 최상의 솔루션은 아니지만 작동합니다."
      ],
      "metadata": {
        "id": "dXVLt0Ct4-5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(tokenizer, type_path, args):\n",
        "    return ImdbDataset(tokenizer=tokenizer, data_dir=args.data_dir, type_path=type_path,  max_len=args.max_seq_length)"
      ],
      "metadata": {
        "id": "bffLSukC5EB4"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 초기화"
      ],
      "metadata": {
        "id": "rAw-Wrjn5r-0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AttributeError: can't set attribute 'hparams'문제에 대응하기 위하여 스택 오버 플로우를 참고하여 버젼을 바꿔보기로한다.\n",
        "\n",
        "- 결과는 실패하였다. 그래서 self.hparams를 수정하였다."
      ],
      "metadata": {
        "id": "0Kq8vQRN6l1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = T5FineTuner(hparams=args)"
      ],
      "metadata": {
        "id": "SzekZzT15qZ2"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "trainer 초기화"
      ],
      "metadata": {
        "id": "E2IMBSOhAD9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(**train_params, auto_lr_find = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "EKcuuTNsAEPJ",
        "outputId": "72962790-c0ae-49d4-d4d5-d86cc61f68b7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-2032253d214d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_lr_find\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/argparse.py\u001b[0m in \u001b[0;36minsert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# all args were already moved to kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsert_env_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Trainer.__init__() got an unexpected keyword argument 'early_stop_callback'"
          ]
        }
      ]
    }
  ]
}