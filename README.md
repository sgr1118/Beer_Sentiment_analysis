# Project : ë§¥ì£¼ ë¦¬ë·° ê°ì • ë¶„ì„

## í”„ë¡œì íŠ¸ í›„ì› : (ì£¼)ëª¨ë‘ì˜ì—°êµ¬ì†Œ, K-ë””ì§€í„¸ í”Œë«í¼
---
ë³¸ í”„ë¡œì íŠ¸ëŠ” ëª¨ë‘ì˜ì—°êµ¬ì†Œì™€ K-ë””ì§€í„¸ í”Œë«í¼ìœ¼ë¡œë¶€í„° ì§€ì›ë°›ì•˜ìŠµë‹ˆë‹¤.

<img src="https://img.shields.io/badge/Python-3.8-blue"><img src="https://img.shields.io/badge/Pytorc%20Lhlightning-1.5.10-blue"><img src="https://img.shields.io/badge/Transformers-4.16.2-blue"><img src="https://img.shields.io/badge/-Colab-yellow)">

## ê°ì • ë¶„ì„ ê²°ê³¼ ì½”ë“œ ì˜ˆì‹œ
```c
import torch
from transformers import T5ForConditionalGeneration, T5Tokenizer
import torch.nn.functional as F

model_path = '/home/beerlab/outputs/simplet5-epoch-2-train-loss-0.0396-val-loss-0.053'
model = T5ForConditionalGeneration.from_pretrained(model_path)
tokenizer = T5Tokenizer.from_pretrained(model_path)

def analyze_sentiment(sentence):
    input_text = "sentiment: " + sentence
    input_ids = tokenizer.encode(input_text, return_tensors='pt')
    input_embeds = model.get_input_embeddings()(input_ids)

    # T5 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê°ì • ë¶„ì„ ìˆ˜í–‰
    output = model.generate(input_ids=input_ids, decoder_inputs_embeds=input_embeds, max_length=200)
    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)

    # í™•ë¥ ì„ ì–»ê¸° ìœ„í•´ ë¡œì§“ ê³„ì‚°
    logits = model(input_ids=input_ids, decoder_inputs_embeds=input_embeds).logits
    probabilities = F.softmax(logits, dim=-1).squeeze()

    sentiment = decoded_output
    emotions = ["Positive", "Negative"]
    emotion_probabilities = probabilities[0].tolist()  # ì²« ë²ˆì§¸ ì›ì†Œë¥¼ ì¶”ì¶œí•˜ì—¬ í™•ë¥ ê°’ìœ¼ë¡œ ì‚¬ìš©
    result = {"sentiment": sentiment, "emotions": dict(zip(emotions, emotion_probabilities))}
    return result

sentences = ['I took a sip and immediately discarded it. How could a beer have such a strong cinnamon flavor?',
             'The taste of this beer embodies the style description quite well.',
             "This beer successfully captures the bitter aroma of coffee, and when you're about to finish a glass, there's a slight dominant sweetness that lingers in your mouth."]
for sentence in sentences:
    predicted_sentiment = analyze_sentiment(sentence)
    print("ë¬¸ì¥:", sentence)
    print("ê°ì •:", predicted_sentiment["sentiment"])
    
ë¬¸ì¥: I took a sip and immediately discarded it. How could a beer have such a strong cinnamon flavor?
ê°ì •: Negative
ë¬¸ì¥: The taste of this beer embodies the style description quite well.
ê°ì •: Positive
ë¬¸ì¥: This beer successfully captures the bitter aroma of coffee, and when you're about to finish a glass, there's a slight dominant sweetness that lingers in your mouth.
ê°ì •: Positive
```

## ğŸ’¡í”„ë¡œì íŠ¸ ì†Œê°œ
```
1ï¸âƒ£ ì£¼ì œ : RateBeer Review ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ë°ì´í„° ë¶„ì„
2ï¸âƒ£ ë°ì´í„°ì…‹ : RateBeer crawling data (ìì²´ ìˆ˜ì§‘)
3ï¸âƒ£ ì»¬ëŸ¼ : Rating, Review, Beer_name 
4ï¸âƒ£ ëª¨ë¸ : SimpleT5(T5)
5ï¸âƒ£ ê°„ë‹¨ ì„¤ëª… : ë§¥ì£¼ ë¦¬ë·° ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°ì • ë¶„ì„ ê²°ê³¼ ì œê³µ
6ï¸âƒ£ ê¸°ëŒ€ íš¨ê³¼ : ìƒí’ˆì— ëŒ€í•œ ê°ì • ë¶„ì„ì„ ê¸°ë°˜ìœ¼ë¡œ ì œí’ˆ ê¸°íš ë° ë§ˆì¼€íŒ… í™œìš©ì— ê·¼ê±°ë¡œ ì‚¬ìš©
```

## ğŸ… í”„ë¡œì íŠ¸ ëª©í‘œ
#### 1. ë°ì´í„° í¬ë¡¤ë§ (ì™„ë£Œ)
#### 2. ë°ì´í„° ì‹œê°í™” ë° EDA (ì™„ë£Œ) 
#### 3. ë°ì´í„° ë¼ë²¨ë§ (ì™„ë£Œ)
#### 4. ë°ì´í„° ì „ì²˜ë¦¬ (ì™„ë£Œ)
#### 5. ê°ì • ë¶„ì„ (ì™„ë£Œ)
#### 6. ê°œì„  ì‚¬í•­ ì ìš© (ì™„ë£Œ)

---
## ì „ì²´ í”„ë¡œì„¸ìŠ¤

### 1. ë°ì´í„° ìˆ˜ì§‘
- Selenium 4.0 ê¸°ë°˜ìœ¼ë¡œ í¬ë¡¤ë§ codeë¥¼ ì œì‘í•˜ì—¬ Rating, Review, Beer_name ìˆ˜ì§‘
- XPATH ê²½ë¡œë¥¼ í†µí•˜ì—¬ Elementsë¥¼ ìˆ˜ì§‘í•œë‹¤.

### 2. ì‹œê°í™” ë° EDA
##### Rating ë¶„í¬ì™€ Review Textì˜ íŠ¹ì´ ì‚¬í•­ í™•ì¸

### 3. ë°ì´í„° ì „ì²˜ë¦¬
- '...'ë§Œ ì‘ì„±ëœ Review ì‚­ì œ
- englishë¡œ ì‘ì„±ë˜ì§€ ì•Šì€ data ì‚­ì œ
- ì—¬ëŸ¬ ë²ˆì˜ ê³µë°±ì„ í•œë²ˆìœ¼ë¡œ ë°”ê¾¸ê¸°
- ë¶ˆìš©ì–´ ì œê±°
- ì§€ë‚˜ì¹˜ê²Œ ê¸´ ë°ì´í„° ì‚­ì œ (len >= 300)
- VADER, Alpaca, GPT API and MultinomialNBì„ ì‚¬ìš©í•˜ì—¬ Labeling ìˆ˜í–‰í•˜ê³  self_labelingê³¼ ë¹„êµ

<Sample Data ì ìš©í•œ Labeling - self_labelingê³¼ ë¹„êµ>
|ë¼ì´ë¸ŒëŸ¬ë¦¬|self_labeling|VADER|Alpaca|GPT API|
|-|-|-|-|-|
|Positive|474|743|346|493|
|Negative|327|181|533|330|
|Neutral|198|76|120|177|

<ì „ì²´ Data ì ìš©í•œ Labeling>
|ë¼ì´ë¸ŒëŸ¬ë¦¬|VADER|Alpaca|GPT API and MultinomialNB|
|-|-|-|-|
|Positive|84732|36897|64021|
|Negative|19306|55934|40520|
|Neutral|8768|19094|3400|

### 4. ê°ì • ë¶„ì„
- Pytoch Multi GPU ì ìš©í•˜ì—¬ Simple T5 (Pytorch Lightning) í•™ìŠµ ìˆ˜í–‰

### 5. ê°œì„  ì‚¬í•­
- [Data Augmentation ê¸°ë²• ì ìš©](https://maelfabien.github.io/machinelearning/NLP_8/#when-should-we-use-data-augmentation)
- SR : ë™ì˜ì–´ êµì²´, RD : ë¬´ì‘ìœ„ ì‚­ì œ, RS : ë¬´ì‘ìœ„ êµì²´, RI : ë¬´ì‘ìœ„ ì‚½ì…
- ë™ì˜ì–´ êµì²´ ë°©ì‹ì´ ê°€ì¥ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆë‹¤.
---
 
## ğŸ—“ï¸ í”„ë¡œì íŠ¸ ì§„í–‰ ì¼ì •

|ë‚´ìš©|M1|M2|M3|M4|M5|M6|M7|
|---|---|---|---|---|---|---|---|
|ë°ì´í„° ìˆ˜ì§‘|â—|â—||||||
|EDA ë° ì‹œê°í™”||â—|â—|||||
|ë°ì´í„° ë¼ë²¨ë§|||â—|||||
|ëª¨ë¸ë§||||â—|â—|â—||
|ê°œì„ ì‚¬í•­ ì ìš©||||||â—|â—|
---
## ğŸ¦„ í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ìë£Œ
#### [1. Hugging_Face_T5_Guide](https://huggingface.co/docs/transformers/model_doc/t5)
#### [2. T5_Paper](https://arxiv.org/pdf/1910.10683v3.pdf)
#### [3. SimpleT5 github](https://github.com/Shivanandroy/simpleT5/tree/main)
#### [4. Data_Labeling_VADER](https://medium.com/analytics-vidhya/sentiment-analysis-with-vader-label-the-unlabeled-data-8dd785225166)
#### [5. Data_Labeling_GPT](https://towardsdatascience.com/can-chatgpt-compete-with-domain-specific-sentiment-analysis-machine-learning-models-cdcd9937b460)
#### [6. Data_Labeling_Alpaca](https://www.youtube.com/watch?v=JzBR8oieyy8&t=117s)
#### [7. The Most Common Evaluation Metrics In NLP](https://medium.com/towards-data-science/the-most-common-evaluation-metrics-in-nlp-ced6a763ac8b)
#### [8. Pytorch Multi GPU](https://medium.com/daangn/pytorch-multi-gpu-%ED%95%99%EC%8A%B5-%EC%A0%9C%EB%8C%80%EB%A1%9C-%ED%95%98%EA%B8%B0-27270617936b)
#### [9. Data Augmentation ê¸°ë²•](https://maelfabien.github.io/machinelearning/NLP_8/#when-should-we-use-data-augmentation)
---
## ğŸ“‘ í”„ë¡œì íŠ¸ ê²°ê³¼ë¬¼ ëª¨ìŒ
|No|ë‚´ìš©|ê¹ƒí—ˆë¸Œ|ê´€ë¦¬ íŒ€ì›|
|-|-|-|-|
|1|ë°ì´í„° ìˆ˜ì§‘|[ğŸ“‚](https://github.com/sgr1118/Beer_Sentiment_anlysis/tree/main/Ratebeer_Crawling)|ì†ê¸°ë½|
|2|ë°ì´í„° ë¼ë²¨ë§|[ğŸ“‚](https://github.com/sgr1118/Beer_Sentiment_anlysis/tree/main/Data_labeling_test)|ì†ê¸°ë½, í•˜ìŠ¹ë²”|
|3|ëª¨ë¸ë§|[ğŸ“‚](https://github.com/sgr1118/Beer_Sentiment_anlysis/tree/main/Sentiment_analsis_result)|ì†ê¸°ë½, í•˜ìŠ¹ë²”|
|4|ê²°ê³¼|[ğŸ“‚](https://github.com/sgr1118/Beer_Sentiment_analysis/tree/main/Sentiment_prediction)|ì†ê¸°ë½|
---
## ğŸ“‘ í•™ìŠµ ê²°ê³¼ ê¸°ë¡
|Model|Accuracy|F1-Score(macro)|Precision(macro)|Recall(macro)|
|---|---|---|---|---|
|T5(Alpaca_labeling)|0.757|0.710|0.733|0.698|
|T5(GPT API and MultinomialNB)|0.908|0.747|0.807|0.723|
|T5(GPT API and MultinomialNB) - RI(ë¬´ì‘ìœ„ ì‚½ì…)|0.904|0.748|0.749|0.747|
|T5(GPT API and MultinomialNB) - RS(ë¬´ì‘ìœ„ êµì²´)|0.914|0.817|0.740|0.767|
|T5(GPT API and MultinomialNB) - SR(ë™ì˜ì–´ êµì²´)|0.915|0.767|0.817|0.740|
|T5(GPT API and MultinomialNB) - RD(ë¬´ì‘ìœ„ ì‚­ì œ)|0.866|0.711|0.772|0.682|

---
## ğŸ“‘ ìµœì¢… í•™ìŠµ ê²°ê³¼ ê¸°ë¡

### Binary Class ë¶„ë¥˜ ê²°ê³¼ 
|Model|Accuracy|F1-Score(macro)|Precision(macro)|Recall(macro)|
|---|---|---|---|---|
|T5(GPT API and MultinomialNB) - SR(ë™ì˜ì–´ êµì²´)|0.946|0.946|0.946|0.946|

### Multi Class ë¶„ë¥˜ ê²°ê³¼ 
|Model|Accuracy|F1-Score(wigthed)|Precision(wigthed)|Recall(wigthed)|
|---|---|---|---|---|
|T5(Alpaca_labeling) - SR, RD|0.915|0.767|0.817|0.740|

---
## ğŸ“‘ í”„ë¡œì íŠ¸ ê°œì„  ìš”êµ¬ ì‚¬í•­

### 1. ë§¥ì£¼ì˜ ì¢…ë¥˜ì— ë”°ë¥¸ ê°ì • ë¶„ì„ ê¸°ì¤€ ì„¸ë¶€í™”
- ì˜ˆë¥¼ ë“¤ì–´ ë¼ê±°ë¼ëŠ” ë§¥ì£¼ ì¢…ë¥˜ ì¤‘ í—¬ë ˆìŠ¤ë¼ëŠ” ê²ƒì´ ìˆë‹¤. í—¬ë ˆìŠ¤ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë§¤ìš° ëª©ë„˜ê¹€ì´ ë„ˆë¬´ í¸í•´ 'watery'í•˜ë‹¤ê³  í•  ìˆ˜ ìˆë‹¤. 
ë‹¤ë§Œ ì´ëŸ° í‘œí˜„ì´ íŠ¹ì§•ì´ ëšœë ·í•œ ë§¥ì£¼ì— ëŒ€í•œ ë¦¬ë·°ì—ì„œëŠ” ë¶€ì •ì ìœ¼ë¡œ ë°›ì•„ë“¤ì—¬ì§ˆ ê°€ëŠ¥ì„±ì´ ìˆë‹¤. ê·¸ëŸ¬ë¯€ë¡œ ë§¥ì£¼ì— íŠ¹ì„±ì„ ë°˜ì˜í•˜ì—¬ ê°ì •ì„ ë¶„ë¥˜í•  í•„ìš”ê°€ ìˆë‹¤.

### 2. ì¤‘ë¦½ì ì¸ ë¦¬ë·° êµ¬ë¶„
- ë§¥ì£¼ ë¦¬ë·°ì—ì„œ ë‹¨ìˆœíˆ ìƒí’ˆì„ ì„¤ëª…í•˜ëŠ” ë‚´ìš©ì´ê±°ë‚˜ ê°ì •ì´ í¬ê²Œ ë‚˜íƒ€ë‚˜ì§€ì•Šì•„ ì¤‘ë¦½ ë¼ë²¨ë§ ì²˜ë¦¬ê°€ í•„ìš”í•  ê²ƒìœ¼ë¡œ ìƒê°í•œë‹¤.
